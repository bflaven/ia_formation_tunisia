{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQHXMbS-SsMT"
   },
   "source": [
    "## Interroger le LLM Claude via une clé d'API\n",
    "\n",
    "### Étape 1: Installation de la bibliothèque Anthropic et importation des modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4395,
     "status": "ok",
     "timestamp": 1744953895547,
     "user": {
      "displayName": "Bruno Flaven",
      "userId": "05777293442111480888"
     },
     "user_tz": -120
    },
    "id": "XRG6fK2HCcvn",
    "outputId": "19e082f9-05c2-491f-c9d1-8f005a79c797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.72.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "# install for openai\n",
    "import os\n",
    "import openai\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1744954038806,
     "user": {
      "displayName": "Bruno Flaven",
      "userId": "05777293442111480888"
     },
     "user_tz": -120
    },
    "id": "1Pnm3aSLTcTh",
    "outputId": "43c573b8-c9a2-4ed8-d329-8f46fcfec964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The OPENAI_API_KEY is UP!\n"
     ]
    }
   ],
   "source": [
    "# Récupération de la clé API depuis les variables d'environnement de Colab\n",
    "# Assurez-vous d'ajouter votre clé API dans l'onglet \"Secrets\" de Colab\n",
    "# CLAUDE_API_KEY = userdata.get('CLAUDE_API_KEY')\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Initialisation du client OpenAI avec votre clé API\n",
    "# client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialisation du client Anthropic avec votre clé API\n",
    "# print(' The CLAUDE_API_KEY is UP!')\n",
    "print(' The OPENAI_API_KEY is UP!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBWry5MiTgyF"
   },
   "source": [
    "## Étape 2: Chargement du prompt avec les variables\n",
    "Définition du prompt exemple avec des variables placeholders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1744953398421,
     "user": {
      "displayName": "Bruno Flaven",
      "userId": "05777293442111480888"
     },
     "user_tz": -120
    },
    "id": "5UQGJp_-TlCQ",
    "outputId": "d8da54e2-a511-47c3-a72d-08f7fc024a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt final:\n",
      "\n",
      "    You are a smart and intelligent journalist. Craft three compelling and unique\n",
      "    titles for an online post about the topic given in the content: '\n",
      "La cinquantaine de pays qui viennent en aide à l'Ukraine en guerre ont promis vendredi de renforcer leur aide militaire,\n",
      "au moment où les États-Unis ont réduit leur soutien. \"Aujourd'hui, j'annonce une enveloppe de 350\n",
      "millions de livres (407 millions d'euros)\", a déclaré à Bruxelles le ministre britannique de la Défense John Healey.\n",
      "Récit d'Eliott Samuel et David Gilberg.\n",
      "' in 'french'.\n",
      "    Ensure to incorporate SEO best practices by including the most common and relevant keywords from\n",
      "    the content in each title. For each proposal, print only the result in a Python dictionary object\n",
      "    with 'title' as a string and 'keywords' as a list. Do not print anything else. Include all three results into a Python list object\n",
      "    like defined below. Output Format:[{\"title\": \"The value of the title\", \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]},\n",
      "    {\"title\": \"The value of the title\", \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]},\n",
      "    {\"title\": \"The value of the title\", \"keywords\":[\"keyword1\", \"keyword2\", \"keyword3\"]}]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Définition des variables directement dans le code principal\n",
    "# language = \"french\"\n",
    "language = \"français\"\n",
    "\n",
    "# CONTENU ARTICLE V1\n",
    "content = \"\"\"\n",
    "La cinquantaine de pays qui viennent en aide à l'Ukraine en guerre ont promis vendredi de renforcer leur aide militaire,\n",
    "au moment où les États-Unis ont réduit leur soutien. \"Aujourd'hui, j'annonce une enveloppe de 350\n",
    "millions de livres (407 millions d'euros)\", a déclaré à Bruxelles le ministre britannique de la Défense John Healey.\n",
    "Récit d'Eliott Samuel et David Gilberg.\n",
    "\"\"\"\n",
    "content = \"\"\"\n",
    "Le conclave qui élira le prochain pape débutera le 7 mai. La date a été annoncée, lundi 28 avril, par le Vatican, où étaient réunis les cardinaux pour la première fois depuis les funérailles du pape François. \n",
    "\n",
    "\n",
    "Durant le conclave, qui se déroule selon un cérémonial bien précis élaboré au cours des siècles, les 135 cardinaux-électeurs se réuniront dans la chapelle Sixtine, au Vatican, pour choisir dans le plus grand secret un successeur à François, mort d'un AVC le lundi de Pâques à 88 ans.\n",
    "\n",
    "Le jésuite argentin a été enterré - comme sept papes avant lui - lors d'une cérémonie privée samedi dans la basilique Sainte-Marie-Majeure, l'une des quatre basiliques pontificales de Rome, où il avait choisi d'être inhumé.\n",
    "\n",
    "Qui lui succèdera pour guider les plus de 1,4 milliard de catholiques ? Le nom du futur évêque de Rome ne sera annoncé \"urbi et orbi\" qu'à l'issue du conclave, réunion à huis clos des \"Princes de l'Eglise\" qui nourrit depuis des siècles l'imagination du commun des mortels.\n",
    "\n",
    "\"On fait confiance à l'Esprit Saint pour qu'on ait le meilleur des papes possible\", dit-il à l'AFP.\n",
    "\n",
    "Messe au lendemain des funérailles du pape François, le 27 avril 2025 sur la place Saint-Pierre, au Vatican.\n",
    "Messe au lendemain des funérailles du pape François, le 27 avril 2025 sur la place Saint-Pierre, au Vatican. © Damien Meyer, AFP\n",
    "Plus de 400 000 personnes ont honoré samedi la mémoire de François, que ce soit lors de la messe place Saint-Pierre au Vatican - à laquelle des dizaines de chefs d'Etat et de gouvernement ont aussi assisté - ou au passage de son cortège funèbre dans les rues de Rome.\n",
    "\n",
    "Vers le conclave\n",
    "\"Il a été le pape du peuple\", résume dans le journal La Repubblica le cardinal italien Giuseppe Versaldi, qualifiant par ailleurs de \"cadeau post-portem\" de François le tête-à-tête entre les présidents américain Donald Trump et ukrainien Volodymyr Zelensky à Saint-Pierre, en marge des funérailles.\n",
    "\n",
    "\n",
    "Depuis les obsèques en grande pompe de François, premier pape sud-américain de l'histoire, le Vatican observe une période de neuf jours de deuil au cours de laquelle des célébrations ont lieu chaque jour à Saint-Pierre, jusqu'au 4 mai.\n",
    "\n",
    "Au terme de celles-ci, les 135 cardinaux électeurs - ceux âgés de moins de 80 ans - seront convoqués pour élire le prélat des prélats.\n",
    "\n",
    "En vertu des règles vaticanes, le conclave devrait s'ouvrir entre le quinzième et le vingtième jour après le décès du pape, soit entre les 5 et 10 mai. Pour le cardinal luxembourgeois Jean-Claude Hollerich, il débutera \"probablement\" le 5 ou le 6 mai.\n",
    "\n",
    "Des cardinaux lors des funérailles du pape François, le 26 avril 2025 sur la place Saint-Pierre, au Vatican.\n",
    "Des cardinaux lors des funérailles du pape François, le 26 avril 2025 sur la place Saint-Pierre, au Vatican. © Tiziana Fabi, AFP\n",
    "Sa date pourrait être annoncée lundi au terme d'une cinquième \"congrégation générale\" - une nouvelle réunion préparatoire des cardinaux, électeurs et non-électeurs - qui doit démarrer à 09 h (07 h GMT).\n",
    "\n",
    "Les deux tiers des voix des votants sont nécessaires. Or, \"nous nous trouvons dans un moment où le catholicisme vit diverses polarisations en son sein et donc je n'imagine pas un conclave très, très rapide\", relève Roberto Regoli, professeur à l'université pontificale grégorienne de Rome.\n",
    "\n",
    "Mais pour le cardinal espagnol Cristobal Lopez Romero, ce conclave offre l'\"opportunité\" de montrer que des films comme \"Conclave ne sont pas la réalité\" : \"Nous devons montrer dans la mesure du possible (...) que nous n'avons pas de secrets, pas de luttes intérieures\", selon Vatican News, le média officiel du Vatican.\n",
    "\n",
    "\n",
    "Pour les experts, la capacité de l'aspirant pape à unir l'Église dans un contexte géopolitique de plus en plus fracturé pourrait être un élément décisif, plus que sa nationalité.\n",
    "\n",
    "Le cardinal italien Pietro Parolin, ex-numéro deux de François, est donné favori par le bookmaker britannique William Hill, devant le Philippin Luis Antonio Tagle, archevêque métropolitain émérite de Manille.\n",
    "\n",
    "Originaire des Philippines, Ricardo Cruz, un informaticien de 44 ans, est venu rendre hommage à François et espère que son successeur viendra d'Asie, même si en tant que catholique il souhaite simplement que les cardinaux choisissent le \"bon pape\".\n",
    "\n",
    "Si François a laissé l'image d'un pape réformiste au franc-parler notoire, rien ne dit que le prochain souverain pontife s'inscrira dans la même ligne, préviennent des experts.\n",
    "\n",
    "Vue aérienne du cercueil du pape François, sur la place Saint-Pierre, le 26 avril 2025 au Vatican.\n",
    "Vue aérienne du cercueil du pape François, sur la place Saint-Pierre, le 26 avril 2025 au Vatican. © Alberto Pizzoli, AFP\n",
    "François, ancien archevêque de Buenos Aires qui défendait ardemment les laissés-pour-compte, était très différent de son prédécesseur Benoît XVI, un intellectuel allemand peu à l'aise en public qui lui-même contrastait avec le charismatique, athlétique et immensément populaire pape polonais Jean-Paul II.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# PROMPT_1 : Depuis un {content} en {language} , générer 3 titres et 5 mots-clés en {language}\n",
    "# prompt_example = f\"\"\"\n",
    "#     You are a smart and intelligent journalist. Craft three compelling and unique\n",
    "#     titles for an online post about the topic given in the content: '{content}' in '{language}'.\n",
    "#     Ensure to incorporate SEO best practices by including the most common and relevant keywords from\n",
    "#     the content in each title. For each proposal, print only the result in a Python dictionary object\n",
    "#     with 'title' as a string and 'keywords' as a list. Do not print anything else. Include all three results into a Python list object\n",
    "#     like defined below. Output Format:[{{\"title\": \"The value of the title\", \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]}},\n",
    "#     {{\"title\": \"The value of the title\", \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]}},\n",
    "#     {{\"title\": \"The value of the title\", \"keywords\":[\"keyword1\", \"keyword2\", \"keyword3\"]}}]\n",
    "#     \"\"\"\n",
    "\n",
    "# PROMPT_2 : Depuis un {content} en {language} , générer 3 titres et 5 mots-clés en {language}\n",
    "prompt_example = f\"\"\"\n",
    "Tu es un journaliste intelligent et astucieux. Rédige trois titres convaincants \n",
    "et uniques pour un article en ligne sur le sujet donné dans le contenu : '{content}' en '{language}'. \n",
    "Assure-toi d'incorporer les meilleures pratiques SEO en incluant les mots-clés les plus courants et \n",
    "pertinents du contenu dans chaque titre. Pour chaque proposition, imprime uniquement le résultat dans un objet dictionnaire \n",
    "Python avec 'title' comme une chaîne de caractères et 'keywords' comme une liste. Inclus tous les trois résultats dans un objet liste \n",
    "Python comme défini ci-dessous. Format de sortie : [{{\"title\": \"La valeur du titre\", \"keywords\": [\"mot-clé1\", \"mot-clé2\", \"mot-clé3\"]}}, \n",
    "{{\"title\": \"La valeur du titre\", \"keywords\": [\"mot-clé1\", \"mot-clé2\", \"mot-clé4\"]}}, {{\"title\": \"La valeur du titre\", \n",
    "\"keywords\": [\"mot-clé1\", \"mot-clé2\", \"mot-clé5\"]}}].\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Affichage du prompt après remplacement des variables\n",
    "print(\"Prompt final:\")\n",
    "print(prompt_example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6djkDSaUkwn"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-7jz4o_VBH0"
   },
   "source": [
    "### Étape 4: Envoi du prompt à ChatGPT et affichage de la réponse\n",
    "Envoi de la requête à l'API de ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 6900,
     "status": "ok",
     "timestamp": 1744954119125,
     "user": {
      "displayName": "Bruno Flaven",
      "userId": "05777293442111480888"
     },
     "user_tz": -120
    },
    "id": "StrukzTiVEsg",
    "outputId": "e0f55cc0-0955-4b3b-9038-68bb14ba7de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Réponse de ChatGPT:\n",
      "[\n",
      "    {\n",
      "        \"title\": \"Engagement accru pour l'Ukraine: 50 pays promettent un renfort militaire malgré le recul américain\",\n",
      "        \"keywords\": [\"Ukraine\", \"aide militaire\", \"50 pays\", \"États-Unis\", \"John Healey\"]\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"350 millions de livres pour l'Ukraine: Le Royaume-Uni booste son soutien face à la diminution américaine\",\n",
      "        \"keywords\": [\"350 millions de livres\", \"John Healey\", \"soutien à l'Ukraine\", \"diminution américaine\", \"Royaume-Uni\"]\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Défense de l'Ukraine: La coalition internationale renforce son aide, analyse de l'engagement britannique\",\n",
      "        \"keywords\": [\"aide à l'Ukraine\", \"coalition internationale\", \"John Healey\", \"renforcement\", \"engagement britannique\"]\n",
      "    }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nresponse = client.messages.create(\\n    model=\"claude-3-opus-20240229\",  # Vous pouvez changer le modèle selon vos besoins\\n    max_tokens=1000,\\n    messages=[\\n        {\"role\": \"user\", \"content\": prompt_example}\\n    ]\\n)\\n\\n# Affichage de la réponse générée par Claude\\nprint(\"\\nRéponse de Claude:\")\\nprint(response.content[0].text)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Envoi de la requête à l'API d'OpenAI\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\", # Vous pouvez changer le modèle selon vos besoins\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_example}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Affichage de la réponse générée par ChatGPT\n",
    "print(\"\\nRéponse de ChatGPT:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "# for claude\n",
    "\n",
    "# response = client.messages.create(\n",
    "#     model=\"claude-3-opus-20240229\",  # Vous pouvez changer le modèle selon vos besoins\n",
    "#     max_tokens=1000,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": prompt_example}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Affichage de la réponse générée par Claude\n",
    "# print(\"\\nRéponse de Claude:\")\n",
    "# print(response.content[0].text)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5mjNI5ALwv8gnSjtynQ5S",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
